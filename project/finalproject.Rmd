---
title: "finalproject"
output: html_document
---

```{r}
library(tidyverse)  # For data manipulation and visualization
library(lubridate)  # For handling dates
library(knitr)      # For nice tables
library(scales)     # For better axis formatting
```



```{r}
pg_crime_2023_2025 <- read_csv("~/Desktop/GitHub/Crime_Incidents_July_2023_to_Present_20250419.csv")
```
```{r}
view(pg_crime_2023_2025)
```

```{r}
Grouped_data <- pg_crime_2023_2025 |>
  group_by(`PGPD Reporting Area`) |>
  summarise(total = n()) |>
  arrange(desc(total))

```

```{r}
Grouped_data|> 
  summarise(mean_crimes = mean(total), sd_crimes = sd(total))
```
```{r}
Grouped_data |> 
  ggplot() + 
  geom_histogram(aes(x = total),  binwidth = 5) +
  geom_vline(aes(xintercept = mean(total)), color = 'red', linetype = "dashed", size = 1)  +
   geom_vline(aes(xintercept = mean(total) - sd(total)), color = 'blue', linetype = "dashed", size = 1) +
   geom_vline(aes(xintercept = mean(total) + sd(total)), color = 'green', linetype = "dashed", size = 1)
```
```{r}
Grouped_data |>
# Check for any missing values
colSums(is.na(Grouped_data))

# Check the date range in our data
min_crimes <- min(Grouped_data$total)
max_crimes <- max(Grouped_data$total)
cat("Data ranges from", min_date, "to", max_date)

```

```{r}
Grouped_data <- Grouped_data |>
  mutate(
    mean_crime = mean(total),
    sd_crime = sd(total),
    z_score = (total - mean_crime) / sd_crime
  )

# Display the data with z-scores
Grouped_data |>
  select('PGPD Reporting Area', total, z_score) |>
  head(10) |>
  kable(digits = 2)
```

Hypothesis: 
If a PGPD Reporting Area has more than 500 crimes in the area, the property value will be lower than if the Reporting Area has less than 400 crimes





1) What does it contain and what time period does it cover?

The data above includes case_id, date of occurrence, type of crime, and multiple different location indicators. The data spans from Jan 1 2023 to April 19th.

2) Which columns will be most important for your analysis?

I assume the most important data will be one of the location indicator columns, as it will allow me to combine this dataset with the property values to fully compare them. 

3) What's missing that you might need or want? What questions do you have about it or need help answering? 

Something missing that would be super helpful is a map number or a neighborhood name, something easily linked to the property value data. 

I just don't know with this data alone, how I could combine or join the two datasets, or even make sure that we have some uniform way of determining location. 
Something like, does the PGPD reporting code corespond to city district numbers etc. 


My other data set seems to be not exportable..?
this is the link
https://sdat.dat.maryland.gov/RealProperty/Pages/default.aspx

I have been messing around a lot with what to sort by and how to best line it up with the crime data. 

1) What does it contain and what time period does it cover?

When I search, I am using the same timeframe, and using a road that occurs a lot in the crime data. It gives aderress, account number, grantee, housing info, and date sold and selling price. 

2) Which columns will be most important for your analysis?
Once again, some location column may be the most important to link the data to crime, but the sale price is obviously super important as well. 

3) Once again I would love this data to have a more defining piece of location. You can search for neighborhood and by certian codes but doesn't come up on the sheet. 

How do I export this data?



